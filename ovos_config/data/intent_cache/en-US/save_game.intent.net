FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.87090728131915162713e-01) (1, -6.06575971476221581513e-02) (2, -5.60859655968332648790e-02) (3, 4.09104860625231106334e-04) (4, -6.62734266439918891928e-03) (5, 1.82883263102541016032e+00) (6, 2.10838551821702469002e-01) (7, -1.08568918060952340765e-01) (8, -7.26346575238699804222e-02) (0, 7.48370638035080162354e+01) (1, 2.97361711954370167010e-01) (2, 4.30626424943700458758e-01) (3, 4.15724578296437885516e-01) (4, 4.41526296531453754657e-01) (5, -6.59410804736311284557e+00) (6, -8.14392987772359333576e+00) (7, -1.00572209530812317624e+00) (8, 9.50090492936619956943e-01) (0, -2.35389428285742802194e-01) (1, -1.06994531292786659860e-01) (2, -2.12849296520853242809e-02) (3, -2.84623421620035302326e-02) (4, -7.57323874937538589480e-03) (5, 1.05537663928135017066e+00) (6, 1.57510365548127695412e-01) (7, -7.58367889639674774838e-02) (8, 7.18395433804993877036e-02) (0, 2.01135929123440748700e-01) (1, -2.13103993014130160821e-01) (2, -1.87102509812149542245e-01) (3, -1.80356962755951338861e-01) (4, -1.05402609483036507898e-01) (5, -2.10291544010034989753e+01) (6, 2.56322809089850278674e-01) (7, -1.58167795496109882258e-02) (8, 1.87903689280485675095e-01) (0, 7.74087579978494644273e-02) (1, -1.28856681379765098533e-02) (2, -3.33442173990696547059e-02) (3, -1.89881257805317518739e-02) (4, -6.08231134805172490854e-02) (5, 2.04065028947257376402e+00) (6, 1.35393525662416025490e-01) (7, -1.80579781633311398092e-01) (8, 1.14364618949370274587e-02) (0, -8.36201851733633039210e-01) (1, -3.89878245076012874826e-01) (2, -2.05139102419686386591e-01) (3, -2.31842594226670334345e-01) (4, -2.30475561698746750361e-01) (5, -2.10045808662764024177e+01) (6, 2.28702982495473206015e+00) (7, -6.53969949164449892987e-02) (8, 1.98331297281799190380e+00) (0, 2.99741508177909288246e-01) (1, 6.46911840026435758233e-01) (2, 6.01608987038192766228e-01) (3, 6.08196022992191331902e-01) (4, 6.16692471389827745476e-01) (5, 7.13477668021061894876e+00) (6, 3.49937722964172381879e+00) (7, 1.31861459366349048627e-01) (8, 3.09170834325727561520e-01) (0, -9.17309326452715734224e-02) (1, -2.83527222357325935087e-02) (2, -1.46591208585315352364e-01) (3, -2.75413391075663947782e-02) (4, -9.60829553089670856947e-02) (5, 6.53896540075115995094e-01) (6, 3.38050244593524007453e-01) (7, -8.70039517685431557092e-02) (8, 2.80979138110351356339e-01) (0, -3.64022580700846365431e+00) (1, -2.67387991305269856479e-02) (2, -2.11113481735793556693e-01) (3, -2.12293467437831367972e-01) (4, -1.61036266898719276908e-01) (5, 8.48129878499920164536e-01) (6, 4.23738231459188263717e-01) (7, -2.07688834134958311139e-01) (8, -1.28964680461814973356e-01) (0, -4.47379574031368021370e-01) (1, -4.78964261481153383282e-02) (2, -1.00273292488752538421e-01) (3, -7.99876264998303915243e-02) (4, -1.10397301384794234436e-02) (5, 5.02058075240589873900e-01) (6, 1.48989867844001339092e-01) (7, -3.85391526934444200725e-02) (8, 3.78404004347924066698e-02) (9, 3.42062877512039453798e-01) (10, -2.07660429899120840824e-01) (11, 4.22494890382933419026e-01) (12, -3.27973524850357744942e-01) (13, 4.22530069892197768233e-01) (14, -3.18766007987494603970e-01) (15, 1.93004178832855283199e-01) (16, 4.69337113955708762347e-01) (17, 4.27138792263492883539e-01) (18, 3.53143163956439964934e-01) (19, 6.66450887926319346377e-01) 
